{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestrating [Rapids](rapids.ai) workflows with [Prefect](prefect.io)\n",
    "\n",
    "https://gist.github.com/ayushdg/0c3cc0f52f5a4c49caec9182ee7089f6\n",
    "\n",
    "This snippet demonstrates a simple Prefect Flow using Rapids to download, read and perform a groupby operation on the [Nyc-Taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page).\n",
    "For more information on setting up Prefect Flows, refer to the [Prefect docs](https://docs.prefect.io/core/getting_started/first-steps.html#thinking-prefectly) which have excellent [tutorials](https://docs.prefect.io/core/advanced_tutorials/) and [examples](https://github.com/PrefectHQ/prefect/tree/master/examples).\n",
    "\n",
    "\n",
    "### Table of Contents:\n",
    "1. [Prefect Task & Flow Setup](#Setting-up-cuDF-tasks)\n",
    "2. [Single GPU, cuDF tasks](#Single-GPU,-cuDF-tasks)\n",
    "3. [Multi GPU, cuDF tasks](#Multi-GPU-cuDF)\n",
    "4. [Multi GPU, dask-cuDF tasks](#Multi-GPU-dask-cuDF)\n",
    "5. [Scheduling runs at intervals](#We-can-also-schedule-runs-at-intervals)\n",
    "6. [Next Steps](#Next-Steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "\n",
    "# choose which GPU to use\n",
    "cupy.cuda.Device(1).use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from prefect import task, Flow, Parameter\n",
    "import prefect\n",
    "import cudf\n",
    "import dask_cudf\n",
    "import gcsfs\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up cuDF tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task()\n",
    "def download_data(source_bucket, destination_path):\n",
    "    if not os.path.exists(destination_path) or len(os.listdir(destination_path)) == 0:\n",
    "        fs = gcsfs.GCSFileSystem()\n",
    "        fs.get(source_bucket, destination_path)\n",
    "    return glob(f\"{destination_path}/*\")\n",
    "\n",
    "\n",
    "@task()\n",
    "def read_data(file_name):\n",
    "    df = cudf.read_csv(file_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "@task()\n",
    "def groupby_chunk(df):\n",
    "    grouped_df = df.groupby(\"Passenger_count\", sort=False).agg(\n",
    "        {\"Tip_amount\": [\"count\", \"sum\"]}\n",
    "    )\n",
    "    return grouped_df\n",
    "\n",
    "\n",
    "@task()\n",
    "def concat_frames(dfs):\n",
    "    return cudf.concat(dfs)\n",
    "\n",
    "\n",
    "@task()\n",
    "def groupby_aggregate(df):\n",
    "    df = df.reset_index()\n",
    "    df.columns = [\"Passenger_count\", \"Tip_count\", \"Tip_sum\"]\n",
    "    grouped_df = df.groupby(\"Passenger_count\", sort=False).agg(\n",
    "        {\"Tip_count\": \"sum\", \"Tip_sum\": \"sum\"}\n",
    "    )\n",
    "    grouped_df[\"Tip_mean\"] = grouped_df[\"Tip_sum\"] / grouped_df[\"Tip_count\"]\n",
    "    return grouped_df[\"Tip_mean\"].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Prefect flow using their [functional API](https://docs.prefect.io/core/getting_started/first-steps.html#functional-api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Flow(\"cuDF NYTaxi Prefect Flow\") as nytaxi_cudf_flow:\n",
    "    source_bucket = Parameter(\"source_bucket\")\n",
    "    destination_path = Parameter(\"destination_path\")\n",
    "\n",
    "    file_list = download_data(source_bucket, destination_path)\n",
    "    dfs = read_data.map(file_list)  # Maps each downloaded file to a read_data operation\n",
    "    grouped_dfs = groupby_chunk.map(\n",
    "        dfs\n",
    "    )  # Maps each dataframe read to a groupby_chunk operation\n",
    "    combined_df = concat_frames(grouped_dfs)\n",
    "    result_df = groupby_aggregate(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the flow\n",
    "\n",
    "NOTE: graphviz에 문제가 있어서 `sudo apt-get install graphviz` 명령으로 이를 별도로 설치했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"362pt\" height=\"479pt\"\n",
       " viewBox=\"0.00 0.00 362.34 479.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 475)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-475 358.335,-475 358.335,4 -4,4\"/>\n",
       "<!-- 140137145471632 -->\n",
       "<g id=\"node1\" class=\"node\"><title>140137145471632</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"182.042\" cy=\"-366\" rx=\"80.6858\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"182.042\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\">download_data</text>\n",
       "</g>\n",
       "<!-- 140137145472144 -->\n",
       "<g id=\"node4\" class=\"node\"><title>140137145472144</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"255.542,-297 108.542,-297 108.542,-261 255.542,-261 255.542,-297\"/>\n",
       "<text text-anchor=\"middle\" x=\"182.042\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">read_data &lt;map&gt;</text>\n",
       "</g>\n",
       "<!-- 140137145471632&#45;&gt;140137145472144 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>140137145471632&#45;&gt;140137145472144</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M182.042,-347.799C182.042,-336.163 182.042,-320.548 182.042,-307.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"185.542,-307.175 182.042,-297.175 178.542,-307.175 185.542,-307.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"216.542\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\">file_name</text>\n",
       "</g>\n",
       "<!-- 140137145474064 -->\n",
       "<g id=\"node2\" class=\"node\"><title>140137145474064</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"275.542,-210 88.5421,-210 88.5421,-174 275.542,-174 275.542,-210\"/>\n",
       "<text text-anchor=\"middle\" x=\"182.042\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">groupby_chunk &lt;map&gt;</text>\n",
       "</g>\n",
       "<!-- 140137145474960 -->\n",
       "<g id=\"node6\" class=\"node\"><title>140137145474960</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"182.042\" cy=\"-105\" rx=\"79.0865\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"182.042\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">concat_frames</text>\n",
       "</g>\n",
       "<!-- 140137145474064&#45;&gt;140137145474960 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>140137145474064&#45;&gt;140137145474960</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M182.042,-173.799C182.042,-162.163 182.042,-146.548 182.042,-133.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"185.542,-133.175 182.042,-123.175 178.542,-133.175 185.542,-133.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"193.042\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">dfs</text>\n",
       "</g>\n",
       "<!-- 140137145471568 -->\n",
       "<g id=\"node3\" class=\"node\"><title>140137145471568</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"89.0421\" cy=\"-453\" rx=\"89.0842\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"89.0421\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">destination_path</text>\n",
       "</g>\n",
       "<!-- 140137145471568&#45;&gt;140137145471632 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>140137145471568&#45;&gt;140137145471632</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M87.7864,-434.576C87.9395,-424.109 89.8414,-411.1 97.0421,-402 102.996,-394.476 110.84,-388.556 119.36,-383.902\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"120.966,-387.012 128.431,-379.495 117.907,-380.716 120.966,-387.012\"/>\n",
       "<text text-anchor=\"middle\" x=\"157.542\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">destination_path</text>\n",
       "</g>\n",
       "<!-- 140137145472144&#45;&gt;140137145474064 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>140137145472144&#45;&gt;140137145474064</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M182.042,-260.799C182.042,-249.163 182.042,-233.548 182.042,-220.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"185.542,-220.175 182.042,-210.175 178.542,-220.175 185.542,-220.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"189.542\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">df</text>\n",
       "</g>\n",
       "<!-- 140137145471440 -->\n",
       "<g id=\"node5\" class=\"node\"><title>140137145471440</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"275.042\" cy=\"-453\" rx=\"79.0865\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"275.042\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\">source_bucket</text>\n",
       "</g>\n",
       "<!-- 140137145471440&#45;&gt;140137145471632 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>140137145471440&#45;&gt;140137145471632</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M256.668,-435.207C242.784,-422.517 223.542,-404.93 208.074,-390.793\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"210.12,-387.921 200.378,-383.758 205.398,-393.088 210.12,-387.921\"/>\n",
       "<text text-anchor=\"middle\" x=\"287.042\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\">source_bucket</text>\n",
       "</g>\n",
       "<!-- 140137145037328 -->\n",
       "<g id=\"node7\" class=\"node\"><title>140137145037328</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"182.042\" cy=\"-18\" rx=\"101.282\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"182.042\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">groupby_aggregate</text>\n",
       "</g>\n",
       "<!-- 140137145474960&#45;&gt;140137145037328 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>140137145474960&#45;&gt;140137145037328</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M182.042,-86.799C182.042,-75.1626 182.042,-59.5479 182.042,-46.2368\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"185.542,-46.1754 182.042,-36.1754 178.542,-46.1755 185.542,-46.1754\"/>\n",
       "<text text-anchor=\"middle\" x=\"189.542\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">df</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f7438c046d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nytaxi_cudf_flow.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the downstream tasks depended on the outputs of the previous tasks, Prefect automatically handled the DAG creation which sequentially map one task to the other. `read_data` and `groupy_chunk` are mapped tasks where each element in the collection of file_names are mapped to these tasks that can run in parallel on a distributed executor such as a [DaskExecutor](https://docs.prefect.io/api/latest/engine/executors.html#daskexecutor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single GPU, cuDF tasks\n",
    "#### Running the flow and viewing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-11 03:07:54+0900] INFO - prefect.FlowRunner | Beginning Flow run for 'cuDF NYTaxi Prefect Flow'\n",
      "[2021-05-11 03:07:54+0900] INFO - prefect.TaskRunner | Task 'destination_path': Starting task run...\n",
      "[2021-05-11 03:07:54+0900] INFO - prefect.TaskRunner | Task 'destination_path': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:07:54+0900] INFO - prefect.TaskRunner | Task 'source_bucket': Starting task run...\n",
      "[2021-05-11 03:07:54+0900] INFO - prefect.TaskRunner | Task 'source_bucket': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:07:54+0900] INFO - prefect.TaskRunner | Task 'download_data': Starting task run...\n",
      "[2021-05-11 03:07:54+0900] INFO - prefect.TaskRunner | Task 'download_data': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:07:54+0900] INFO - prefect.TaskRunner | Task 'read_data': Starting task run...\n",
      "[2021-05-11 03:07:54+0900] INFO - prefect.TaskRunner | Task 'read_data': Finished task run for task with final state: 'Mapped'\n",
      "[2021-05-11 03:07:54+0900] INFO - prefect.TaskRunner | Task 'read_data[0]': Starting task run...\n",
      "[2021-05-11 03:07:59+0900] INFO - prefect.TaskRunner | Task 'read_data[0]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:07:59+0900] INFO - prefect.TaskRunner | Task 'read_data[1]': Starting task run...\n",
      "[2021-05-11 03:07:59+0900] INFO - prefect.TaskRunner | Task 'read_data[1]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:07:59+0900] INFO - prefect.TaskRunner | Task 'read_data[2]': Starting task run...\n",
      "[2021-05-11 03:07:59+0900] INFO - prefect.TaskRunner | Task 'read_data[2]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:07:59+0900] INFO - prefect.TaskRunner | Task 'read_data[3]': Starting task run...\n",
      "[2021-05-11 03:07:59+0900] INFO - prefect.TaskRunner | Task 'read_data[3]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:07:59+0900] INFO - prefect.TaskRunner | Task 'read_data[4]': Starting task run...\n",
      "[2021-05-11 03:07:59+0900] INFO - prefect.TaskRunner | Task 'read_data[4]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:07:59+0900] INFO - prefect.TaskRunner | Task 'read_data[5]': Starting task run...\n",
      "[2021-05-11 03:08:00+0900] INFO - prefect.TaskRunner | Task 'read_data[5]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:00+0900] INFO - prefect.TaskRunner | Task 'read_data[6]': Starting task run...\n",
      "[2021-05-11 03:08:00+0900] INFO - prefect.TaskRunner | Task 'read_data[6]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:00+0900] INFO - prefect.TaskRunner | Task 'read_data[7]': Starting task run...\n",
      "[2021-05-11 03:08:00+0900] INFO - prefect.TaskRunner | Task 'read_data[7]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:00+0900] INFO - prefect.TaskRunner | Task 'read_data[8]': Starting task run...\n",
      "[2021-05-11 03:08:00+0900] INFO - prefect.TaskRunner | Task 'read_data[8]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:00+0900] INFO - prefect.TaskRunner | Task 'read_data[9]': Starting task run...\n",
      "[2021-05-11 03:08:00+0900] INFO - prefect.TaskRunner | Task 'read_data[9]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:00+0900] INFO - prefect.TaskRunner | Task 'read_data[10]': Starting task run...\n",
      "[2021-05-11 03:08:00+0900] INFO - prefect.TaskRunner | Task 'read_data[10]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:00+0900] INFO - prefect.TaskRunner | Task 'read_data[11]': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'read_data[11]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk': Finished task run for task with final state: 'Mapped'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[0]': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[0]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[1]': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[1]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[2]': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[2]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[3]': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[3]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[4]': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[4]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[5]': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[5]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[6]': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[6]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[7]': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[7]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[8]': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[8]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[9]': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[9]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[10]': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[10]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[11]': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_chunk[11]': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'concat_frames': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'concat_frames': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_aggregate': Starting task run...\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.TaskRunner | Task 'groupby_aggregate': Finished task run for task with final state: 'Success'\n",
      "[2021-05-11 03:08:01+0900] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    }
   ],
   "source": [
    "flow_run1 = nytaxi_cudf_flow.run(\n",
    "    source_bucket=\"gs://anaconda-public-data/nyc-taxi/csv/2014/green_tripdata*.csv\",\n",
    "    destination_path=\"./nyc-taxi/green_tripdata/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of a flow run can be used to view the results of each stage. \n",
    "\n",
    "In this case, we query the result of the task returning `result_df` from the output of `flow_run1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tip_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passenger_count</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.370795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.073249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.178949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.184562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.044996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.072943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.276358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.665341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.843497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.316867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Tip_mean\n",
       "Passenger_count          \n",
       "0                0.370795\n",
       "1                1.073249\n",
       "2                1.178949\n",
       "3                1.184562\n",
       "4                1.044996\n",
       "5                1.072943\n",
       "6                1.276358\n",
       "7                0.665341\n",
       "8                0.843497\n",
       "9                1.316867"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_run1.result[result_df].result.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the Prefect flow to multiple GPUs <a class=\"anchor\" id=\"Multi-GPU-cuDF\"></a>\n",
    "\n",
    "Prefect has a tight integration with [Dask](https://dask.org) allowing users to scale tasks on a Dask cluster. Rapids also has a tight dask integration to scale workflows to multiple GPUs using [dask-cuda](https://github.com/rapidsai/dask-cuda) which builds on the dask-worker to make it easy to use with cuda enabled GPUs. \n",
    "\n",
    "There are multiple ways to scale a Prefect flow out to multiple GPUs (Single and Multi Node)\n",
    "\n",
    "#### Option 1: Starting a LocalCUDACluster directly using `DaskExecutor` (Single Node only)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect.executors import DaskExecutor\n",
    "\n",
    "executor = DaskExecutor(\n",
    "    cluster_class=\"dask_cuda.LocalCUDACluster\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the flow on multiple GPUs on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-11 03:08:01+0900] INFO - prefect.FlowRunner | Beginning Flow run for 'cuDF NYTaxi Prefect Flow'\n",
      "[2021-05-11 03:08:02+0900] INFO - prefect.DaskExecutor | Creating a new Dask cluster with `dask_cuda.local_cuda_cluster.LocalCUDACluster`...\n",
      "[2021-05-11 03:08:04+0900] INFO - prefect.DaskExecutor | The Dask dashboard is available at http://127.0.0.1:8787/status\n",
      "[2021-05-11 03:08:33+0900] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    }
   ],
   "source": [
    "flow_run2 = nytaxi_cudf_flow.run(\n",
    "    source_bucket=\"gs://anaconda-public-data/nyc-taxi/csv/2014/green_tripdata*.csv\",\n",
    "    destination_path=\"./nyc-taxi/green_tripdata/\",\n",
    "    executor=executor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHY this error? MemoryError: std::bad_alloc: CUDA error at: /home/kywch/miniconda3/envs/saturn/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorIllegalAddress an illegal memory access was encountered\n",
    "\n",
    "#flow_run2.result[result_df].result.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del (flow_run1, flow_run2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Start a dask-cuda cluster through any preferred method and point the `DaskExecutor` object to the scheduler address\n",
    "\n",
    "For the purposes of this example a single node `LocalCUDACluster` is used. This could easily be replaced by a multi node cluster each running `dask-cuda-worker` and connected to a common `dask-scheduler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_cuda import LocalCUDACluster\n",
    "\n",
    "cluster = LocalCUDACluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect.executors import DaskExecutor\n",
    "\n",
    "executor = DaskExecutor(address=cluster.scheduler_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-11 03:08:35+0900] INFO - prefect.FlowRunner | Beginning Flow run for 'cuDF NYTaxi Prefect Flow'\n",
      "[2021-05-11 03:08:35+0900] INFO - prefect.DaskExecutor | Connecting to an existing Dask cluster at tcp://127.0.0.1:33249\n",
      "[2021-05-11 03:08:59+0900] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    }
   ],
   "source": [
    "flow_run3 = nytaxi_cudf_flow.run(\n",
    "    source_bucket=\"gs://anaconda-public-data/nyc-taxi/csv/2014/green_tripdata*.csv\",\n",
    "    destination_path=\"./nyc-taxi/green_tripdata/\",\n",
    "    executor=executor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Using the dask_cudf api to leverage muti-gpu dataframe operations directly <a class=\"anchor\" id=\"Multi-GPU-dask-cuDF\"></a>\n",
    "\n",
    "The examples above used `cuDF` a single GPU dataframe library each performing a small task and scaled by scheduling multiple tasks using dask. In the real world, datasets can often be much larger where a single GPU may not be sufficient to perform this unit of work (Task).The dask-cuDF distributed dataframe library (built on top of Dask Dataframe) can also be used with Prefect tasks just as easily.\n",
    "\n",
    "#### Setting up dask-cuDF tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import worker_client\n",
    "\n",
    "\n",
    "@task(checkpoint=False)\n",
    "def dask_read_data(file_names):\n",
    "    with worker_client() as client:\n",
    "        return dask_cudf.read_csv(file_names)\n",
    "\n",
    "\n",
    "@task()\n",
    "def dask_groupby_task(ddf):\n",
    "    with worker_client() as client:\n",
    "        return ddf.groupby(\"Passenger_count\").Tip_amount.mean().compute().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a dask-cuDF Prefect flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Flow(\"Dask-cuDF NYTaxi Prefect Flow\") as nytaxi_dask_cudf_flow:\n",
    "    source_bucket = Parameter(\"source_bucket\")\n",
    "    destination_path = Parameter(\"destination_path\")\n",
    "\n",
    "    file_list = download_data(source_bucket, destination_path)\n",
    "    ddf = dask_read_data(file_list)\n",
    "    result_df = dask_groupby_task(ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"362pt\" height=\"305pt\"\n",
       " viewBox=\"0.00 0.00 362.34 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-301 358.335,-301 358.335,4 -4,4\"/>\n",
       "<!-- 140137156132752 -->\n",
       "<g id=\"node1\" class=\"node\"><title>140137156132752</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"172.293\" cy=\"-192\" rx=\"80.6858\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.293\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">download_data</text>\n",
       "</g>\n",
       "<!-- 140137156129936 -->\n",
       "<g id=\"node5\" class=\"node\"><title>140137156129936</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"172.293\" cy=\"-105\" rx=\"83.6854\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.293\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">dask_read_data</text>\n",
       "</g>\n",
       "<!-- 140137156132752&#45;&gt;140137156129936 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>140137156132752&#45;&gt;140137156129936</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.293,-173.799C172.293,-162.163 172.293,-146.548 172.293,-133.237\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"175.793,-133.175 172.293,-123.175 168.793,-133.175 175.793,-133.175\"/>\n",
       "<text text-anchor=\"middle\" x=\"210.293\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">file_names</text>\n",
       "</g>\n",
       "<!-- 140136364244624 -->\n",
       "<g id=\"node2\" class=\"node\"><title>140136364244624</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"172.293\" cy=\"-18\" rx=\"100.983\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.293\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">dask_groupby_task</text>\n",
       "</g>\n",
       "<!-- 140136393002064 -->\n",
       "<g id=\"node3\" class=\"node\"><title>140136393002064</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"79.293\" cy=\"-279\" rx=\"79.0865\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"79.293\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">source_bucket</text>\n",
       "</g>\n",
       "<!-- 140136393002064&#45;&gt;140137156132752 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>140136393002064&#45;&gt;140137156132752</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M83.9176,-261.024C87.5035,-250.468 93.3878,-237.199 102.293,-228 108.007,-222.097 114.928,-217.029 122.166,-212.733\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"124.32,-215.546 131.436,-207.697 120.978,-209.395 124.32,-215.546\"/>\n",
       "<text text-anchor=\"middle\" x=\"155.293\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">source_bucket</text>\n",
       "</g>\n",
       "<!-- 140136392999056 -->\n",
       "<g id=\"node4\" class=\"node\"><title>140136392999056</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"265.293\" cy=\"-279\" rx=\"89.0842\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"265.293\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">destination_path</text>\n",
       "</g>\n",
       "<!-- 140136392999056&#45;&gt;140137156132752 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>140136392999056&#45;&gt;140137156132752</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M246.919,-261.207C233.035,-248.517 213.792,-230.93 198.325,-216.793\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"200.371,-213.921 190.629,-209.758 195.649,-219.088 200.371,-213.921\"/>\n",
       "<text text-anchor=\"middle\" x=\"284.793\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">destination_path</text>\n",
       "</g>\n",
       "<!-- 140137156129936&#45;&gt;140136364244624 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>140137156129936&#45;&gt;140136364244624</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.293,-86.799C172.293,-75.1626 172.293,-59.5479 172.293,-46.2368\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"175.793,-46.1754 172.293,-36.1754 168.793,-46.1755 175.793,-46.1754\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.293\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">ddf</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f740a20b1d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nytaxi_dask_cudf_flow.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `dask_read_data` and `dask_groupby_task` operations work directly with dask-cudf dataframes and use the entire cluster for the task computations.\n",
    "\n",
    "#### Running the Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-11 03:08:59+0900] INFO - prefect.FlowRunner | Beginning Flow run for 'Dask-cuDF NYTaxi Prefect Flow'\n",
      "[2021-05-11 03:08:59+0900] INFO - prefect.DaskExecutor | Connecting to an existing Dask cluster at tcp://127.0.0.1:33249\n",
      "[2021-05-11 03:09:01+0900] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    }
   ],
   "source": [
    "executor = DaskExecutor(address=cluster.scheduler_address)\n",
    "\n",
    "flow_run4 = nytaxi_dask_cudf_flow.run(\n",
    "    source_bucket=\"gs://anaconda-public-data/nyc-taxi/csv/2014/green_tripdata*.csv\",\n",
    "    destination_path=\"./nyc-taxi/green_tripdata/\",\n",
    "    executor=executor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why this error? -- RuntimeError: merge_sort: failed to synchronize: cudaErrorIllegalAddress: an illegal memory access was encountered\n",
    "\n",
    "#flow_run4.result[result_df].result.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del (flow_run3, flow_run4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also schedule runs at intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime\n",
    "from prefect.schedules import IntervalSchedule\n",
    "\n",
    "# Schedule runs at intervals of 1 minute\n",
    "schedule = IntervalSchedule(\n",
    "    start_date=datetime.utcnow() + timedelta(seconds=1),\n",
    "    interval=timedelta(minutes=1),\n",
    ")\n",
    "\n",
    "nytaxi_dask_cudf_flow.schedule = schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-11 03:09:01+0900] INFO - prefect.Dask-cuDF NYTaxi Prefect Flow | Waiting for next scheduled run at 2021-05-10T18:09:02.602572+00:00\n",
      "[2021-05-11 03:09:02+0900] INFO - prefect.FlowRunner | Beginning Flow run for 'Dask-cuDF NYTaxi Prefect Flow'\n",
      "[2021-05-11 03:09:02+0900] INFO - prefect.DaskExecutor | Connecting to an existing Dask cluster at tcp://127.0.0.1:33249\n",
      "[2021-05-11 03:09:05+0900] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n",
      "[2021-05-11 03:09:05+0900] INFO - prefect.Dask-cuDF NYTaxi Prefect Flow | Waiting for next scheduled run at 2021-05-10T18:10:02.602572+00:00\n",
      "[2021-05-11 03:10:02+0900] INFO - prefect.FlowRunner | Beginning Flow run for 'Dask-cuDF NYTaxi Prefect Flow'\n",
      "[2021-05-11 03:10:02+0900] INFO - prefect.DaskExecutor | Connecting to an existing Dask cluster at tcp://127.0.0.1:33249\n",
      "[2021-05-11 03:10:05+0900] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n",
      "[2021-05-11 03:10:05+0900] INFO - prefect.Dask-cuDF NYTaxi Prefect Flow | Waiting for next scheduled run at 2021-05-10T18:11:02.602572+00:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b697c590ff7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msource_bucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gs://anaconda-public-data/nyc-taxi/csv/2014/green_tripdata*.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdestination_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./nyc-taxi/green_tripdata/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mexecutor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/envs/saturn/lib/python3.7/site-packages/prefect/core/flow.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameters, run_on_schedule, runner_cls, **kwargs)\u001b[0m\n\u001b[1;32m   1265\u001b[0m             \u001b[0mrunner_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunner_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0mrun_on_schedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_on_schedule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m         )\n\u001b[1;32m   1269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/saturn/lib/python3.7/site-packages/prefect/core/flow.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, parameters, runner_cls, run_on_schedule, **kwargs)\u001b[0m\n\u001b[1;32m   1066\u001b[0m                         \u001b[0;34m\"Waiting for next scheduled run at {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_run_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m                     )\n\u001b[0;32m-> 1068\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnaptime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "interval_run = nytaxi_dask_cudf_flow.run(\n",
    "    source_bucket=\"gs://anaconda-public-data/nyc-taxi/csv/2014/green_tripdata*.csv\",\n",
    "    destination_path=\"./nyc-taxi/green_tripdata/\",\n",
    "    executor=executor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Next steps: Prefect [server orchestration](https://docs.prefect.io/orchestration/) <a class=\"anchor\" id=\"Next-Steps\"></a>\n",
    "\n",
    "The existing flow can be registered to a Prefect backend (server or cloud) which can be used to monitor, schedule and execute multiple Prefect flows across project and environments.\n",
    "\n",
    "When using the Local server as the backend, the flow can be modified as follows:\n",
    "- Setup an execution environment for the flow eg: `LocalEnvironment`\n",
    "\n",
    "```python\n",
    "from prefect.environments import LocalEnvironment\n",
    "from prefect.engine.executors import DaskExecutor\n",
    "\n",
    "executor = DaskExecutor(address=\"{scheduler_address}\")\n",
    "environment = LocalEnvironment(executor=executor)\n",
    "```\n",
    "\n",
    "- Register the flow to a project\n",
    "    ```python\n",
    "    flow.register(\"project_name\")\n",
    "    ```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
